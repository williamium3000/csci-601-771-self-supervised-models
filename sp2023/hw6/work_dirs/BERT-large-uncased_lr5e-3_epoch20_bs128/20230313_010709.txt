srun: job 1586599 queued and waiting for resources
srun: job 1586599 has been allocated resources
Found cached dataset boolq (/u/yli8/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=128, device='cuda', experiment='train', graph_name='work_dirs/BERT-large-uncased_lr5e-3_epoch20_bs128//plot', lr=0.005, model='BERT-large-uncased', num_epochs=20, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 846.74it/s]
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 14.8kB/s]
Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████| 571/571 [00:00<00:00, 412kB/s]
Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 4.06MB/s]
Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 5.55MB/s]
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 10.5M/1.34G [00:00<00:16, 83.0MB/s]Downloading pytorch_model.bin:   2%|▏         | 21.0M/1.34G [00:00<00:15, 85.6MB/s]Downloading pytorch_model.bin:   2%|▏         | 31.5M/1.34G [00:00<00:15, 87.2MB/s]Downloading pytorch_model.bin:   3%|▎         | 41.9M/1.34G [00:00<00:15, 85.1MB/s]Downloading pytorch_model.bin:   4%|▍         | 52.4M/1.34G [00:00<00:14, 87.2MB/s]Downloading pytorch_model.bin:   5%|▍         | 62.9M/1.34G [00:00<00:15, 83.9MB/s]Downloading pytorch_model.bin:   5%|▌         | 73.4M/1.34G [00:00<00:15, 83.3MB/s]Downloading pytorch_model.bin:   6%|▌         | 83.9M/1.34G [00:00<00:15, 83.1MB/s]Downloading pytorch_model.bin:   7%|▋         | 94.4M/1.34G [00:01<00:14, 84.4MB/s]Downloading pytorch_model.bin:   8%|▊         | 105M/1.34G [00:01<00:14, 85.4MB/s] Downloading pytorch_model.bin:   9%|▊         | 115M/1.34G [00:01<00:14, 86.4MB/s]Downloading pytorch_model.bin:   9%|▉         | 126M/1.34G [00:01<00:13, 87.9MB/s]Downloading pytorch_model.bin:  10%|█         | 136M/1.34G [00:01<00:13, 89.1MB/s]Downloading pytorch_model.bin:  11%|█         | 147M/1.34G [00:01<00:13, 89.6MB/s]Downloading pytorch_model.bin:  12%|█▏        | 157M/1.34G [00:01<00:13, 87.3MB/s]Downloading pytorch_model.bin:  12%|█▏        | 168M/1.34G [00:01<00:13, 85.9MB/s]Downloading pytorch_model.bin:  13%|█▎        | 178M/1.34G [00:02<00:14, 83.3MB/s]Downloading pytorch_model.bin:  14%|█▍        | 189M/1.34G [00:02<00:13, 85.4MB/s]Downloading pytorch_model.bin:  15%|█▍        | 199M/1.34G [00:02<00:13, 84.9MB/s]Downloading pytorch_model.bin:  16%|█▌        | 210M/1.34G [00:02<00:14, 79.4MB/s]Downloading pytorch_model.bin:  16%|█▋        | 220M/1.34G [00:02<00:14, 78.5MB/s]Downloading pytorch_model.bin:  17%|█▋        | 231M/1.34G [00:02<00:14, 75.8MB/s]Downloading pytorch_model.bin:  18%|█▊        | 241M/1.34G [00:02<00:14, 77.3MB/s]Downloading pytorch_model.bin:  19%|█▊        | 252M/1.34G [00:03<00:14, 76.9MB/s]Downloading pytorch_model.bin:  19%|█▉        | 262M/1.34G [00:03<00:13, 81.3MB/s]Downloading pytorch_model.bin:  20%|██        | 273M/1.34G [00:03<00:12, 83.4MB/s]Downloading pytorch_model.bin:  21%|██        | 283M/1.34G [00:03<00:12, 83.4MB/s]Downloading pytorch_model.bin:  22%|██▏       | 294M/1.34G [00:03<00:12, 82.3MB/s]Downloading pytorch_model.bin:  23%|██▎       | 304M/1.34G [00:03<00:12, 82.2MB/s]Downloading pytorch_model.bin:  23%|██▎       | 315M/1.34G [00:03<00:12, 81.9MB/s]Downloading pytorch_model.bin:  24%|██▍       | 325M/1.34G [00:03<00:13, 77.1MB/s]Downloading pytorch_model.bin:  25%|██▍       | 336M/1.34G [00:04<00:14, 68.2MB/s]Downloading pytorch_model.bin:  26%|██▌       | 346M/1.34G [00:04<00:13, 72.2MB/s]Downloading pytorch_model.bin:  27%|██▋       | 357M/1.34G [00:04<00:12, 76.3MB/s]Downloading pytorch_model.bin:  27%|██▋       | 367M/1.34G [00:04<00:12, 79.9MB/s]Downloading pytorch_model.bin:  28%|██▊       | 377M/1.34G [00:04<00:11, 81.7MB/s]Downloading pytorch_model.bin:  29%|██▉       | 388M/1.34G [00:04<00:11, 82.4MB/s]Downloading pytorch_model.bin:  30%|██▉       | 398M/1.34G [00:04<00:12, 75.6MB/s]Downloading pytorch_model.bin:  30%|███       | 409M/1.34G [00:05<00:12, 74.6MB/s]Downloading pytorch_model.bin:  31%|███       | 419M/1.34G [00:05<00:12, 73.7MB/s]Downloading pytorch_model.bin:  32%|███▏      | 430M/1.34G [00:05<00:11, 77.1MB/s]Downloading pytorch_model.bin:  33%|███▎      | 440M/1.34G [00:05<00:12, 73.9MB/s]Downloading pytorch_model.bin:  34%|███▎      | 451M/1.34G [00:05<00:11, 77.8MB/s]Downloading pytorch_model.bin:  34%|███▍      | 461M/1.34G [00:05<00:11, 79.9MB/s]Downloading pytorch_model.bin:  35%|███▌      | 472M/1.34G [00:05<00:11, 77.9MB/s]Downloading pytorch_model.bin:  36%|███▌      | 482M/1.34G [00:05<00:11, 75.6MB/s]Downloading pytorch_model.bin:  37%|███▋      | 493M/1.34G [00:06<00:10, 79.3MB/s]Downloading pytorch_model.bin:  37%|███▋      | 503M/1.34G [00:06<00:11, 74.1MB/s]Downloading pytorch_model.bin:  38%|███▊      | 514M/1.34G [00:06<00:11, 72.5MB/s]Downloading pytorch_model.bin:  39%|███▉      | 524M/1.34G [00:06<00:10, 74.9MB/s]Downloading pytorch_model.bin:  40%|███▉      | 535M/1.34G [00:06<00:10, 77.0MB/s]Downloading pytorch_model.bin:  41%|████      | 545M/1.34G [00:06<00:10, 79.8MB/s]Downloading pytorch_model.bin:  41%|████▏     | 556M/1.34G [00:06<00:09, 80.3MB/s]Downloading pytorch_model.bin:  42%|████▏     | 566M/1.34G [00:07<00:09, 82.5MB/s]Downloading pytorch_model.bin:  43%|████▎     | 577M/1.34G [00:07<00:09, 83.7MB/s]Downloading pytorch_model.bin:  44%|████▎     | 587M/1.34G [00:07<00:09, 83.3MB/s]Downloading pytorch_model.bin:  44%|████▍     | 598M/1.34G [00:07<00:08, 84.9MB/s]Downloading pytorch_model.bin:  45%|████▌     | 608M/1.34G [00:07<00:08, 82.0MB/s]Downloading pytorch_model.bin:  46%|████▌     | 619M/1.34G [00:07<00:08, 82.5MB/s]Downloading pytorch_model.bin:  47%|████▋     | 629M/1.34G [00:07<00:08, 85.9MB/s]Downloading pytorch_model.bin:  48%|████▊     | 640M/1.34G [00:07<00:08, 82.0MB/s]Downloading pytorch_model.bin:  48%|████▊     | 650M/1.34G [00:08<00:08, 81.5MB/s]Downloading pytorch_model.bin:  49%|████▉     | 661M/1.34G [00:08<00:08, 82.4MB/s]Downloading pytorch_model.bin:  50%|████▉     | 671M/1.34G [00:08<00:08, 80.7MB/s]Downloading pytorch_model.bin:  51%|█████     | 682M/1.34G [00:08<00:08, 82.9MB/s]Downloading pytorch_model.bin:  51%|█████▏    | 692M/1.34G [00:08<00:07, 81.7MB/s]Downloading pytorch_model.bin:  52%|█████▏    | 703M/1.34G [00:08<00:07, 84.1MB/s]Downloading pytorch_model.bin:  53%|█████▎    | 713M/1.34G [00:08<00:07, 82.7MB/s]Downloading pytorch_model.bin:  54%|█████▍    | 724M/1.34G [00:08<00:07, 83.7MB/s]Downloading pytorch_model.bin:  55%|█████▍    | 734M/1.34G [00:09<00:07, 82.5MB/s]Downloading pytorch_model.bin:  55%|█████▌    | 744M/1.34G [00:09<00:07, 85.1MB/s]Downloading pytorch_model.bin:  56%|█████▌    | 755M/1.34G [00:09<00:06, 85.4MB/s]Downloading pytorch_model.bin:  57%|█████▋    | 765M/1.34G [00:09<00:07, 80.6MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 776M/1.34G [00:09<00:07, 80.3MB/s]Downloading pytorch_model.bin:  58%|█████▊    | 786M/1.34G [00:09<00:06, 82.3MB/s]Downloading pytorch_model.bin:  59%|█████▉    | 797M/1.34G [00:09<00:06, 84.2MB/s]Downloading pytorch_model.bin:  60%|██████    | 807M/1.34G [00:09<00:06, 78.7MB/s]Downloading pytorch_model.bin:  61%|██████    | 818M/1.34G [00:10<00:06, 80.5MB/s]Downloading pytorch_model.bin:  62%|██████▏   | 828M/1.34G [00:10<00:06, 83.8MB/s]Downloading pytorch_model.bin:  62%|██████▏   | 839M/1.34G [00:10<00:06, 78.8MB/s]Downloading pytorch_model.bin:  63%|██████▎   | 849M/1.34G [00:10<00:06, 77.6MB/s]Downloading pytorch_model.bin:  64%|██████▍   | 860M/1.34G [00:10<00:08, 56.9MB/s]Downloading pytorch_model.bin:  65%|██████▌   | 881M/1.34G [00:10<00:05, 84.9MB/s]Downloading pytorch_model.bin:  67%|██████▋   | 902M/1.34G [00:11<00:05, 82.6MB/s]Downloading pytorch_model.bin:  68%|██████▊   | 912M/1.34G [00:11<00:05, 81.0MB/s]Downloading pytorch_model.bin:  69%|██████▊   | 923M/1.34G [00:11<00:05, 78.1MB/s]Downloading pytorch_model.bin:  69%|██████▉   | 933M/1.34G [00:11<00:05, 77.1MB/s]Downloading pytorch_model.bin:  70%|███████   | 944M/1.34G [00:11<00:05, 78.6MB/s]Downloading pytorch_model.bin:  71%|███████   | 954M/1.34G [00:11<00:04, 80.3MB/s]Downloading pytorch_model.bin:  72%|███████▏  | 965M/1.34G [00:11<00:04, 81.1MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 975M/1.34G [00:12<00:04, 81.3MB/s]Downloading pytorch_model.bin:  73%|███████▎  | 986M/1.34G [00:12<00:04, 81.3MB/s]Downloading pytorch_model.bin:  74%|███████▍  | 996M/1.34G [00:12<00:04, 77.1MB/s]Downloading pytorch_model.bin:  75%|███████▍  | 1.01G/1.34G [00:12<00:04, 80.5MB/s]Downloading pytorch_model.bin:  76%|███████▌  | 1.02G/1.34G [00:12<00:04, 79.6MB/s]Downloading pytorch_model.bin:  76%|███████▋  | 1.03G/1.34G [00:12<00:03, 82.4MB/s]Downloading pytorch_model.bin:  77%|███████▋  | 1.04G/1.34G [00:12<00:03, 83.3MB/s]Downloading pytorch_model.bin:  78%|███████▊  | 1.05G/1.34G [00:13<00:03, 83.6MB/s]Downloading pytorch_model.bin:  79%|███████▊  | 1.06G/1.34G [00:13<00:03, 82.9MB/s]Downloading pytorch_model.bin:  80%|███████▉  | 1.07G/1.34G [00:13<00:03, 85.0MB/s]Downloading pytorch_model.bin:  80%|████████  | 1.08G/1.34G [00:13<00:03, 86.4MB/s]Downloading pytorch_model.bin:  81%|████████  | 1.09G/1.34G [00:13<00:02, 85.8MB/s]Downloading pytorch_model.bin:  82%|████████▏ | 1.10G/1.34G [00:13<00:02, 84.2MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 1.11G/1.34G [00:13<00:02, 80.7MB/s]Downloading pytorch_model.bin:  83%|████████▎ | 1.12G/1.34G [00:13<00:02, 80.5MB/s]Downloading pytorch_model.bin:  84%|████████▍ | 1.13G/1.34G [00:14<00:02, 82.6MB/s]Downloading pytorch_model.bin:  85%|████████▍ | 1.14G/1.34G [00:14<00:02, 79.5MB/s]Downloading pytorch_model.bin:  86%|████████▌ | 1.15G/1.34G [00:14<00:02, 80.7MB/s]Downloading pytorch_model.bin:  87%|████████▋ | 1.16G/1.34G [00:14<00:02, 83.1MB/s]Downloading pytorch_model.bin:  87%|████████▋ | 1.17G/1.34G [00:14<00:02, 80.8MB/s]Downloading pytorch_model.bin:  88%|████████▊ | 1.18G/1.34G [00:14<00:01, 81.2MB/s]Downloading pytorch_model.bin:  89%|████████▉ | 1.20G/1.34G [00:14<00:01, 78.9MB/s]Downloading pytorch_model.bin:  90%|████████▉ | 1.21G/1.34G [00:14<00:01, 80.7MB/s]Downloading pytorch_model.bin:  90%|█████████ | 1.22G/1.34G [00:15<00:01, 80.7MB/s]Downloading pytorch_model.bin:  91%|█████████ | 1.23G/1.34G [00:15<00:01, 81.6MB/s]Downloading pytorch_model.bin:  92%|█████████▏| 1.24G/1.34G [00:15<00:01, 83.8MB/s]Downloading pytorch_model.bin:  93%|█████████▎| 1.25G/1.34G [00:15<00:01, 84.1MB/s]Downloading pytorch_model.bin:  94%|█████████▎| 1.26G/1.34G [00:15<00:01, 83.9MB/s]Downloading pytorch_model.bin:  94%|█████████▍| 1.27G/1.34G [00:15<00:00, 85.0MB/s]Downloading pytorch_model.bin:  95%|█████████▌| 1.28G/1.34G [00:15<00:00, 83.0MB/s]Downloading pytorch_model.bin:  96%|█████████▌| 1.29G/1.34G [00:15<00:00, 84.7MB/s]Downloading pytorch_model.bin:  97%|█████████▋| 1.30G/1.34G [00:16<00:00, 82.1MB/s]Downloading pytorch_model.bin:  97%|█████████▋| 1.31G/1.34G [00:16<00:00, 80.4MB/s]Downloading pytorch_model.bin:  98%|█████████▊| 1.32G/1.34G [00:16<00:00, 82.9MB/s]Downloading pytorch_model.bin:  99%|█████████▉| 1.33G/1.34G [00:16<00:00, 84.3MB/s]Downloading pytorch_model.bin: 100%|█████████▉| 1.34G/1.34G [00:16<00:00, 83.6MB/s]Downloading pytorch_model.bin: 100%|██████████| 1.34G/1.34G [00:16<00:00, 81.0MB/s]
Some weights of the model checkpoint at BERT-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at BERT-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.566875}
Traceback (most recent call last):
  File "classification.py", line 285, in <module>
    train_acc_rec, eval_acc_rec = train(
  File "classification.py", line 184, in train
    val_accuracy = evaluate_model(mymodel, validation_dataloader, device)
  File "classification.py", line 95, in evaluate_model
    output = model(input_ids=input_ids, attention_mask=attention_mask)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 1563, in forward
    outputs = self.bert(
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 1019, in forward
    encoder_outputs = self.encoder(
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 609, in forward
    layer_outputs = layer_module(
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 537, in forward
    layer_output = apply_chunking_to_forward(
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/transformers/pytorch_utils.py", line 249, in apply_chunking_to_forward
    return forward_fn(*input_tensors)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 550, in feed_forward_chunk
    layer_output = self.output(intermediate_output, attention_output)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 464, in forward
    hidden_states = self.LayerNorm(hidden_states + input_tensor)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/normalization.py", line 173, in forward
    return F.layer_norm(
  File "/u/yli8/.conda/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py", line 2346, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 44.43 GiB total capacity; 42.76 GiB already allocated; 40.75 MiB free; 42.76 GiB reserved in total by PyTorch)
srun: error: gpub076: task 0: Exited with exit code 1
